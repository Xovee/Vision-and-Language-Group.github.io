<!DOCTYPE html>
<html>


<head>
  <!-- <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> -->
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CFM(Song and Gao) - Team</title>
  <meta name="description" content="CFM : Team members">
  <link rel="canonical" href="index.html">
  <link rel="stylesheet" href="../css/bootstrap.min.css">
  <link rel="stylesheet" href="../css/main.css">
  <link rel="shortcut icon" type="image/x-icon" href="../images/assests/favicon.ico">
</head>


<body>

  <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="navbar-background-container">
      <div class="container-fluid">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1"
            aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>

          <a class="navbar-brand" href="../index.html">Center for Future Media, UESTC</a>
        </div>
        <div class="collapse navbar-collapse" id="navbar-collapse-1">
          <ul class="nav navbar-nav navbar-right">
            <li><a href="../index.html" class="hvr-underline-from-center">Home</a></li>
            <li><a href="../research/index.html" class="hvr-underline-from-center">Research</a></li>
            <li><a href="../members/index.html" class="hvr-underline-from-center">Members</a></li>
            <li><a href="../publications/index.html" class="hvr-underline-from-center">Publications</a></li>
            <li><a href="../seminars/index.html" class="hvr-underline-from-center">Seminars</a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>

  <div class="container-fluid">
    <div class="row">
      <div id="gridid" class="col-sm-12">
        <center>
          <h1 id="group-members">Seminars</h1>
        </center>



        <h2 id="New">New</h2>
         <div class="row">

          <!--TODO: 1: Add PPT link to all blocks, including img
                    2: Add a script to calculate the ealier ppts-->

          <div class="col-sm-12 clearfix">
          	<center>
          		
          	            <p><img src="../images/seminars/2020-2-lrm.png" class="img-responsive" width="70%" /></p>
          	</center>

            <strong>Speaker:</strong> Ruimin Lang&emsp;[<a
              href="https://pan.baidu.com/s/1T4zx_5iC0Is_Fom8FVzjsw">PPT (password: 90li)</a>]<br>
            <strong>Topic:</strong>3D Self-Attention for Unsupervised Video Quantization<br>
            <strong>Date:</strong>April 30, 2020<br>
            <strong>Abstract: </strong>
            Unsupervised video quantization is to compress the original videos to compact binary codes so that video retrieval can be conducted in an efficient way. In this paper, we make a first attempt to combine quantization method with video retrieval called 3D-UVQ, which obtains high retrieval accuracy with low storage cost. In the proposed framework, we address two main problems:<br>
            1) how to design an effective pipeline to perceive video contextual information for video features extraction; <br>
            2) how to quantize these features for efficient retrieval.

            </ul>
          </div>
      </div>

         <div class="row">

          <!--TODO: 1: Add PPT link to all blocks, including img
                    2: Add a script to calculate the ealier ppts-->

          <div class="col-sm-12 clearfix">
          	<center>
              <p><img src="../images/seminars/2020-2-zzl.png" class="img-responsive" width="70%" /></p>        		
          	</center>

            <strong>Speaker:</strong> Zhilong Zhou&emsp;[<a
              href="https://pan.baidu.com/s/1bk47-UCVsWb_t_yL7ySsXQ">PPT (password: vqyn) </a>]<br>
            <strong>Topic:</strong>Monocular 3D Face Reconstruction<br>
            <strong>Date:</strong>April 30, 2020<br>
            <strong>Abstract: </strong>
3D face reconstruction from 2D images enables many exciting applications, such as face recognition , face puppetry, face reenactment  virtual make-up , etc. However, 3D face shape and texture inference from 2D images, especially from a single image, is an ill-posed problem since some 3D information is lost after the imaging process. 3D morphable model (3DMM)  learned from a collection of 3D face scans is often adopted as a strong prior assumption for this problem. This report will introduce the monocular 3D face reconstruction, 3D morphable models and review some representative works.


            </ul>
          </div>
      </div>



        <h4><a href="all_seminars.html">... see all seminars</a></h4>
        <div id="footer" class="panel">
          <div class="panel-footer">
            <div class="container-fluid">
              <div class="row">
                <center>
                  <div class="col-sm-12">
                    Contact: Room A305, innovation center, University of Electronic Science and Technology of China (<a
                      href="https://www.amap.com/search?query=%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E6%B8%85%E6%B0%B4%E6%B2%B3%E6%A0%A1%E5%8C%BA%E5%88%9B%E6%96%B0%E4%B8%AD%E5%BF%83&city=510100&geoobj=103.851502%7C30.542145%7C104.389832%7C30.782536&zoom=12">Maps</a>)
                    <br />
                    If there are any bugs, please contact <a
                      href="mailto:qilong.zhangdl@gmail.com">qilong.zhangdl@gmail.com</a>. Thank you!
                    (2019-9-25) <br />

                </center>
              </div>
            </div>
          </div>
        </div>
      </div>

      <script src="../js/jquery.min.js"></script>
      <script src="../js/bootstrap.min.js"></script>


</body>

</html>