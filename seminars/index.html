<!DOCTYPE html>
<html>


<head>
  <!-- <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> -->
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Vision and Language Group@CFM - Team</title>
  <meta name="description" content="CFM : Team members">
  <link rel="canonical" href="index.html">
  <link rel="stylesheet" href="../css/bootstrap.min.css">
  <link rel="stylesheet" href="../css/main.css">
  <link rel="shortcut icon" type="image/x-icon" href="../images/assests/favicon.ico">
</head>


<body>

  <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="navbar-background-container">
      <div class="container-fluid">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1"
            aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>

          <a class="navbar-brand" href="../index.html">Vision and Language Group@CFM, UESTC</a>
        </div>
        <div class="collapse navbar-collapse" id="navbar-collapse-1">
          <ul class="nav navbar-nav navbar-right">
            <li><a href="../index.html" class="hvr-underline-from-center">Home</a></li>
            <li><a href="../research/index.html" class="hvr-underline-from-center">Research</a></li>
            <li><a href="../members/index.html" class="hvr-underline-from-center">Members</a></li>
            <li><a href="../publications/index.html" class="hvr-underline-from-center">Publications</a></li>
            <li><a href="../seminars/index.html" class="hvr-underline-from-center">Seminars</a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>

  <div class="container-fluid">
    <div class="row">
      <div id="gridid" class="col-sm-12">
        <center>
          <h1 id="group-members">Seminars</h1>
        </center>



        <h2 id="New">New</h2>
         <div class="row">

          <!--TODO: 1: Add PPT link to all blocks, including img
                    2: Add a script to calculate the ealier ppts-->

          <div class="col-sm-12 clearfix">
          	<center>
          		
          	 <p><img src="../images/seminars/2020-21-zjk.jpg" class="img-responsive" width="70%" /></p>
          	</center>

            <strong>Speaker:</strong>Jinkuan Zhu&emsp;[<a
              href="https://pan.baidu.com/s/12bS6Xj1eLSDRhnJCdnsocw">PPT</a>&<a
              href="https://pan.baidu.com/s/1H370B_r0T8_tCIO-Ras0dg">Video</a>(password: 1234)]<br>
            <strong>Topic:</strong>Graph based Cross-Modal Retrieval<br>
            <strong>Date:</strong>Oct 30, 2020<br>
            <strong>Abstract: </strong>
            Cross-Modal Retrieval aims to retrieve the texts (images) that describe the most relevant contents for a given image (text) query. Most existing works represent correspondence between image and text by utilizing coarse correspondence between words and objects. I am going to introduce two graph based methods that learn fine-grained phrase correspondence for this matching task.
            </ul>
          </div>
      </div>

         <div class="row">

          <!--TODO: 1: Add PPT link to all blocks, including img
                    2: Add a script to calculate the ealier ppts-->

          <div class="col-sm-12 clearfix">
          	<center>
              <p><img src="../images/seminars/2020-21-ly.jpg" class="img-responsive" width="70%" /></p>
          	</center>

            <strong>Speaker:</strong>Ye Liu&emsp;[<a
              href="https://pan.baidu.com/s/1BOHyhWkRQHC-QPobMh5txw">PPT</a>&<a
              href="https://pan.baidu.com/s/1iKvcRmTEjt6y1RmqPGZ3iA">Video</a>(password: 1234) ]<br>
            <strong>Topic:</strong>CIKM2020 通用目标检测对抗攻击竞赛经验分享<br>
            <strong>Date:</strong>Oct 30, 2020<br>
            <strong>Abstract: </strong>
            深度神经网络已经在各种视觉识别问题上取得了最先进的性能。尽管取得了极大成功，但深度神经网络很容易遭受输入上微小和不可察觉的干扰导致误分类（这些输入也被称为对抗样本），深度神经网络模型的安全问题也在业内引起了不少的担忧。为了发现目标检测模型的脆弱性、为此领域的工作者敲响警钟。本次阿里安全举办了CIKM2020 通用目标检测的对抗攻击的比赛，该比赛是全球首个结合黑盒白盒场景，针对多种目标检测模型的对抗攻击竞赛。该比赛采用COCO数据集。任务是通过向原始图像中添加对抗补丁（adversarial patch）的方式，使得典型的目标检测模型不能够检测到图像中的物体，绕过目标定位。为了更好的评价选手的攻击效果，这次比赛创造了全新的得分计算准则。除了加入攻击成功率之外，还对添加补丁的数量和大小进行了约束。选手添加的补丁数量、修改的像素和模型识别到的包围盒越少，则代表攻击更加成功，得分则越高。为了保证比赛的难度，比赛选取了4个近期的State-of-the-art检测模型作为攻击目标，包括两个白盒模型——YOLO v4和Faster RCNN和另外两个未知的黑盒模型。
            </ul>
          </div>
      </div>







        <h4><a href="all_seminars.html">... see all seminars</a></h4>
        <div id="footer" class="panel">
          <div class="panel-footer">
            <div class="container-fluid">
              <div class="row">
                <center>
                  <div class="col-sm-12">
                    Contact: Room A305, innovation center, University of Electronic Science and Technology of China (<a
                      href="https://www.amap.com/search?query=%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E6%B8%85%E6%B0%B4%E6%B2%B3%E6%A0%A1%E5%8C%BA%E5%88%9B%E6%96%B0%E4%B8%AD%E5%BF%83&city=510100&geoobj=103.851502%7C30.542145%7C104.389832%7C30.782536&zoom=12">Maps</a>)
                    <br />
                    If there are any bugs, please contact <a
                      href="mailto:qilong.zhangdl@gmail.com">qilong.zhangdl@gmail.com</a>. Thank you!
                    (2019-9-25) <br />

                </center>
              </div>
            </div>
          </div>
        </div>
      </div>

      <script src="../js/jquery.min.js"></script>
      <script src="../js/bootstrap.min.js"></script>


</body>

</html>