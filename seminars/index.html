<!DOCTYPE html>
<html>


<head>
  <!-- <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> -->
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CFM(Song and Gao) - Team</title>
  <meta name="description" content="CFM : Team members">
  <link rel="canonical" href="index.html">
  <link rel="stylesheet" href="../css/bootstrap.min.css">
  <link rel="stylesheet" href="../css/main.css">
  <link rel="shortcut icon" type="image/x-icon" href="../images/assests/favicon.ico">
</head>


<body>

  <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="navbar-background-container">
      <div class="container-fluid">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1"
            aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>

          <a class="navbar-brand" href="../index.html">Center for Future Media, UESTC</a>
        </div>
        <div class="collapse navbar-collapse" id="navbar-collapse-1">
          <ul class="nav navbar-nav navbar-right">
            <li><a href="../index.html" class="hvr-underline-from-center">Home</a></li>
            <li><a href="../research/index.html" class="hvr-underline-from-center">Research</a></li>
            <li><a href="../members/index.html" class="hvr-underline-from-center">Members</a></li>
            <li><a href="../publications/index.html" class="hvr-underline-from-center">Publications</a></li>
            <li><a href="../seminars/index.html" class="hvr-underline-from-center">Seminars</a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>

  <div class="container-fluid">
    <div class="row">
      <div id="gridid" class="col-sm-12">
        <center>
          <h1 id="group-members">Seminars</h1>
        </center>



        <h2 id="New">New</h2>
         <div class="row">

          <!--TODO: 1: Add PPT link to all blocks, including img
                    2: Add a script to calculate the ealier ppts-->

          <div class="col-sm-12 clearfix">
          	<center>
          		
          	            <p><img src="../images/seminars/2020-7-nh.png" class="img-responsive" width="70%" /></p>
          	</center>

            <strong>Speaker:</strong> Hao Ni&emsp;[<a
              href="https://pan.baidu.com/s/19W8P5X0LDxyPFvW8rxozIw">PPT (password: o9mi)</a>]<br>
            <strong>Topic:</strong>Unsupervised Person Re-ID<br>
            <strong>Date:</strong>June 12, 2020<br>
            <strong>Abstract: </strong>
            TPerson re-identification（Person Re-ID）refers to the cross-camera pedestrian retrieval task. Due to its important application in the field of video security, it has been extensively studied in recent years. With the development of deep learning, the performance of Person Re-ID has reached a very high level in public data set. However, most of the existing research focuses on the supervised Person Re-ID models. Due to the bad performance, unsupervised Pedestrian re-identification is still difficult to put into practical applications. 


            </ul>
          </div>
      </div>

         <div class="row">

          <!--TODO: 1: Add PPT link to all blocks, including img
                    2: Add a script to calculate the ealier ppts-->

          <div class="col-sm-12 clearfix">
          	<center>
              <p><img src="../images/seminars/2020-7-mlx.png" class="img-responsive" width="70%" /></p>        		
          	</center>

            <strong>Speaker:</strong> Lanxin Miao&emsp;[<a
              href="https://pan.baidu.com/s/1a6w0K4lN7isPHwckzVnz5w">PPT (password: msoi) </a>]<br>
            <strong>Topic:</strong>Image-text matching<br>
            <strong>Date:</strong>June 12, 2020<br>
            <strong>Abstract: </strong>
image-text matching Image-text matching has been a hot research topic bridging the vision and language areas. The major method is to map images and texts into the same semantic space in which they can be compared. However, there are still some challengs in this area. One is to measure the similarity between different modalities of data. Besdies, the current representation of image usually lacks global semantic concepts as in its corresponding text caption.  Moreover, although some models can achieve impressive caption quality, they still suffer from poor attention grounding. To address these issues, new models and methods were proposed. Three papers related to this area will be introduced in this presentation.
Two parts are included in my report:<br>
(1) Introduction of Image-Text Matching<br>
(2) Three related papers




            </ul>
          </div>
      </div>



         <div class="row">

          <!--TODO: 1: Add PPT link to all blocks, including img
                    2: Add a script to calculate the ealier ppts-->

          <div class="col-sm-12 clearfix">
          	<center>
              <p><img src="../images/seminars/2020-7-zzx.png" class="img-responsive" width="70%" /></p>        		
          	</center>

            <strong>Speaker:</strong> Zhixin Zhai&emsp;[<a
              href="https://pan.baidu.com/s/1yR1Z7qcv8y002IuIiUXTSA">PPT (password: tv5w) </a>]<br>
            <strong>Topic:</strong>Single Image Super-Resolution<br>
            <strong>Date:</strong>June 12, 2020<br>
            <strong>Abstract: </strong>
Single Image Super-Resolution（SISR）has improved a lot since the neural networks were involved. A kind of structures and modules of the tasks have been proposed in the past fewer years, some of which have already been essential when we design a new SR network.
In this report, I will briefly introduce the task, then list the basic architectures and modules via some representative works. Next, I will detailedly introduce three GAN-based SR algorithms, and finally conclude the future work for the task. Four parts could be included in my report:<br>
(1) A brief overview about SISR.<br>
(2) Introduce the supervised SISR task and SRGAN、ESRGAN, and conclude the basic architectures and modules.<br>
(3) Introduce the blind SISR task and CinCGAN.<br>
(4) Introduce the future work in SR task.




            </ul>
          </div>
      </div>



        <h4><a href="all_seminars.html">... see all seminars</a></h4>
        <div id="footer" class="panel">
          <div class="panel-footer">
            <div class="container-fluid">
              <div class="row">
                <center>
                  <div class="col-sm-12">
                    Contact: Room A305, innovation center, University of Electronic Science and Technology of China (<a
                      href="https://www.amap.com/search?query=%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E6%B8%85%E6%B0%B4%E6%B2%B3%E6%A0%A1%E5%8C%BA%E5%88%9B%E6%96%B0%E4%B8%AD%E5%BF%83&city=510100&geoobj=103.851502%7C30.542145%7C104.389832%7C30.782536&zoom=12">Maps</a>)
                    <br />
                    If there are any bugs, please contact <a
                      href="mailto:qilong.zhangdl@gmail.com">qilong.zhangdl@gmail.com</a>. Thank you!
                    (2019-9-25) <br />

                </center>
              </div>
            </div>
          </div>
        </div>
      </div>

      <script src="../js/jquery.min.js"></script>
      <script src="../js/bootstrap.min.js"></script>


</body>

</html>