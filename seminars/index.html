<!DOCTYPE html>
<html>


<head>
  <!-- <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> -->
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CFM(Song and Gao) - Team</title>
  <meta name="description" content="CFM : Team members">
  <link rel="canonical" href="index.html">
  <link rel="stylesheet" href="../css/bootstrap.min.css">
  <link rel="stylesheet" href="../css/main.css">
  <link rel="shortcut icon" type="image/x-icon" href="../images/assests/favicon.ico">
</head>


<body>

  <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="navbar-background-container">
      <div class="container-fluid">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1"
            aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>

          <a class="navbar-brand" href="../index.html">Center for Future Media, UESTC</a>
        </div>
        <div class="collapse navbar-collapse" id="navbar-collapse-1">
          <ul class="nav navbar-nav navbar-right">
            <li><a href="../index.html" class="hvr-underline-from-center">Home</a></li>
            <li><a href="../research/index.html" class="hvr-underline-from-center">Research</a></li>
            <li><a href="../members/index.html" class="hvr-underline-from-center">Members</a></li>
            <li><a href="../publications/index.html" class="hvr-underline-from-center">Publications</a></li>
            <li><a href="../seminars/index.html" class="hvr-underline-from-center">Seminars</a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>

  <div class="container-fluid">
    <div class="row">
      <div id="gridid" class="col-sm-12">
        <center>
          <h1 id="group-members">Seminars</h1>
        </center>



        <h2 id="New">New</h2>
         <div class="row">

          <!--TODO: 1: Add PPT link to all blocks, including img
                    2: Add a script to calculate the ealier ppts-->

          <div class="col-sm-12 clearfix">
          	<center>
          		
          	            <p><img src="../images/seminars/2020-4-zyx.png" class="img-responsive" width="70%" /></p>
          	</center>

            <strong>Speaker:</strong> Yixuan Zhou&emsp;[<a
              href="https://pan.baidu.com/s/1prOJriX1sHQGKq8FS-7RRw">PPT (password: 88hn)</a>]<br>
            <strong>Topic:</strong>Transparent Object Matting<br>
            <strong>Date:</strong>May 15, 2020<br>
            <strong>Abstract: </strong>
            Image matting has been widely used in image editing and film production. However, most of the existing methods are tailored for opaque(不透明) objects, and cannot handle transparent objects whose appearances depend on how light is refracted from the background. It is highly ill-posed, if not impossible, to estimate an accurate environment matte for transparent objects from a single image with an arbitrary background. The report will introduce a CNN based method for this problom, which called Transparent Object Matting Network(TOM-Net).
			Three parts are included in this report:<br>
			(1) A brief introduce about image. <br>
			(2) The datasets propoesd in this paper. <br>
			(3) introduce details of the TOM-Net.


            </ul>
          </div>
      </div>

         <div class="row">

          <!--TODO: 1: Add PPT link to all blocks, including img
                    2: Add a script to calculate the ealier ppts-->

          <div class="col-sm-12 clearfix">
          	<center>
              <p><img src="../images/seminars/2020-4-ctm.png" class="img-responsive" width="70%" /></p>        		
          	</center>

            <strong>Speaker:</strong> Tangming Chen&emsp;[<a
              href="https://pan.baidu.com/s/1WTPnNms831roIbVo7eD6kQ">PPT (password: q446) </a>]<br>
            <strong>Topic:</strong>Visual dialog<br>
            <strong>Date:</strong>May 15, 2020<br>
            <strong>Abstract: </strong>
Vision and language understanding has become an attractive and challenging interdisciplinary field in computer vision and natural language processing. Resently, researchers have achieved inspiring progress in a range of vision-language tasks. Visual dialog is one of the prototype tasks. It can help the AI agent to see and communicate. Today, I will briefly introduce this task and focus on some recent works so that the listeners have a generative understanding.   Two parts are included in my report:<br>
			(1) An simple overview about visual dialog <br>
			(2)  Introduce two papers in this area




            </ul>
          </div>
      </div>



        <h4><a href="all_seminars.html">... see all seminars</a></h4>
        <div id="footer" class="panel">
          <div class="panel-footer">
            <div class="container-fluid">
              <div class="row">
                <center>
                  <div class="col-sm-12">
                    Contact: Room A305, innovation center, University of Electronic Science and Technology of China (<a
                      href="https://www.amap.com/search?query=%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E6%B8%85%E6%B0%B4%E6%B2%B3%E6%A0%A1%E5%8C%BA%E5%88%9B%E6%96%B0%E4%B8%AD%E5%BF%83&city=510100&geoobj=103.851502%7C30.542145%7C104.389832%7C30.782536&zoom=12">Maps</a>)
                    <br />
                    If there are any bugs, please contact <a
                      href="mailto:qilong.zhangdl@gmail.com">qilong.zhangdl@gmail.com</a>. Thank you!
                    (2019-9-25) <br />

                </center>
              </div>
            </div>
          </div>
        </div>
      </div>

      <script src="../js/jquery.min.js"></script>
      <script src="../js/bootstrap.min.js"></script>


</body>

</html>