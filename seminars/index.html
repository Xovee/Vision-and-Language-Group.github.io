<!DOCTYPE html>
<html>


<head>
  <!-- <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> -->
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CFM(Song and Gao) - Team</title>
  <meta name="description" content="CFM : Team members">
  <link rel="canonical" href="index.html">
  <link rel="stylesheet" href="../css/bootstrap.min.css">
  <link rel="stylesheet" href="../css/main.css">
  <link rel="shortcut icon" type="image/x-icon" href="../images/assests/favicon.ico">
</head>


<body>

  <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="navbar-background-container">
      <div class="container-fluid">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1"
            aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>

          <a class="navbar-brand" href="../index.html">Center for Future Media, UESTC</a>
        </div>
        <div class="collapse navbar-collapse" id="navbar-collapse-1">
          <ul class="nav navbar-nav navbar-right">
            <li><a href="../index.html" class="hvr-underline-from-center">Home</a></li>
            <li><a href="../research/index.html" class="hvr-underline-from-center">Research</a></li>
            <li><a href="../members/index.html" class="hvr-underline-from-center">Members</a></li>
            <li><a href="../publications/index.html" class="hvr-underline-from-center">Publications</a></li>
            <li><a href="../seminars/index.html" class="hvr-underline-from-center">Seminars</a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>

  <div class="container-fluid">
    <div class="row">
      <div id="gridid" class="col-sm-12">
        <center>
          <h1 id="group-members">Seminars</h1>
        </center>



        <h2 id="New">New</h2>
         <div class="row">

          <!--TODO: 1: Add PPT link to all blocks, including img
                    2: Add a script to calculate the ealier ppts-->

          <div class="col-sm-12 clearfix">
          	<center>
          		
          	            <p><img src="../images/seminars/2020-8-dy.png" class="img-responsive" width="70%" /></p>
          	</center>

            <strong>Speaker:</strong> Yan Dai&emsp;[<a
              href="https://pan.baidu.com/s/18i5QRNPDvoO1waJzJo9HIw">PPT</a>(password: pkxb)<a
              href="https://pan.baidu.com/s/1SGSXkV9vKlQfSjNjzDlwlw">Video</a>(password: z7np) ]<br>
            <strong>Topic:</strong>Multi-person Pose Estimation<br>
            <strong>Date:</strong>June 19, 2020<br>
            <strong>Abstract: </strong>
Despite of the recent great progress on multi-person pose estimation, existing solutions still undergo serious degradation under the condition of “crowded scenes”, where RGB images capture complex real-world scenes with highly overlapped people, severe occlusions, diverse postures and scale variations. In this work, we focus on two main problems: 1) how to remove the joints-of-interference from a given person proposal; and 2) how to infer the ambiguous joints. To tackle these problems, we propose a new pipeline named Relation based Pose Graph Network (RPGNet). Unlike existing works that directly predict joints-of-target by labeling joints-of-interference as false positive, we encourage all joints to be predicted and model their relation through a multi-joints relation parser (MRP) for joints-of-interference removal. This new pipeline will largely relieve the confusion of the joints estimation model when seeing identical joints with totally distinct labels(e.g., the identical hand exists in two bounding boxes). Furthermore, human beings can well estimate the joints with ambiguity by looking at the surrounding regions. For example, human can easily infer the location of ‘neck’ after seeing 
‘head’ and ‘shoulder’. Inspired by this, we propose a joints refinement machine (JRM) with commonsense knowledge to refine pose estimation results for handling ambiguous joints. Extensive experiments on pose estimation benchmarks demonstrate that our method significantly outperforms existing state-of-the-art methods by a large margin. 


            </ul>
          </div>
      </div>

         <div class="row">

          <!--TODO: 1: Add PPT link to all blocks, including img
                    2: Add a script to calculate the ealier ppts-->

          <div class="col-sm-12 clearfix">
          	<center>
              <p><img src="../images/seminars/2020-8-wxh.png" class="img-responsive" width="70%" /></p>        		
          	</center>

            <strong>Speaker:</strong> Xuanhan Wang&emsp;[<a
              href="https://pan.baidu.com/s/1GmL9sOYaynDRKV_KJvTugg">PPT</a>(password: cq5y)<a
              href="https://pan.baidu.com/s/1SGSXkV9vKlQfSjNjzDlwlw">Video</a>(password: z7np) ]<br>

            <strong>Topic:</strong>基于人类常识的稠密姿态估计<br>
            <strong>Date:</strong>June 19, 2020<br>
            <strong>Abstract: </strong>
In this presentation, we address the multi-person densepose estimation
problem, which aims at learning dense correspondences between
2D pixels of human body and 3D surface. It still poses several challenges
due to real-world scenes with scale variations, occlusion
and insufficient annotations. In particular, we address two main
problems: 1) how to design a simple yet effective pipeline for densepose
estimation; and 2) how to equip this pipeline with the ability
of handing the issues of limited annotation and class-imbalanced
labels. To tackle these problems, we develop a novel densepose
estimation framework based on a two-stage pipeline, called Knowledge
Transfer Network (KTN). Unlike existing works which directly
propagate the pyramidal base features of regions, we enhance their
representation power by a multi-instance decoder (MID). MID
can well distinguish the target instance from other interference instances
and background. Then, we introduce a knowledge transfer
machine (KTM), which improves densepose estimation by
utilizing the external commonsense knowledge. Notably, with the
help of our knowledge transfer machine (KTM), current densepose
estimation systems (either based on RCNN or fully-convolutional
frameworks) can be improved in terms of the accuracy of human
densepose estimation. Solid experiments on densepose estimation
benchmarks demonstrate the superiority and generalizability of
our approach.




            </ul>
          </div>
      </div>







        <h4><a href="all_seminars.html">... see all seminars</a></h4>
        <div id="footer" class="panel">
          <div class="panel-footer">
            <div class="container-fluid">
              <div class="row">
                <center>
                  <div class="col-sm-12">
                    Contact: Room A305, innovation center, University of Electronic Science and Technology of China (<a
                      href="https://www.amap.com/search?query=%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E6%B8%85%E6%B0%B4%E6%B2%B3%E6%A0%A1%E5%8C%BA%E5%88%9B%E6%96%B0%E4%B8%AD%E5%BF%83&city=510100&geoobj=103.851502%7C30.542145%7C104.389832%7C30.782536&zoom=12">Maps</a>)
                    <br />
                    If there are any bugs, please contact <a
                      href="mailto:qilong.zhangdl@gmail.com">qilong.zhangdl@gmail.com</a>. Thank you!
                    (2019-9-25) <br />

                </center>
              </div>
            </div>
          </div>
        </div>
      </div>

      <script src="../js/jquery.min.js"></script>
      <script src="../js/bootstrap.min.js"></script>


</body>

</html>