<!DOCTYPE html>
<html>

<head>
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CFM(Song and Gao) - Research</title>
  <meta name="description" content="CMF(Song and Gao) -- Research.">
  <link rel="stylesheet" href="../css/main.css">
  <link rel="canonical" href="index.html">
<link rel="shortcut icon" type ="image/x-icon" href="../images/favicon.ico">
<style type="text/css">
  .navbar-background-container {
    background-image: url("../css/background.jpg");
    background-size: cover;
  }
</style>




</head>


  <body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
      <div class="navbar-background-container">
  <div class="container-fluid">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1" aria-expanded="false">
    <span class="sr-only">Toggle navigation</span>
    <span class="icon-bar"></span>
    <span class="icon-bar"></span>
    <span class="icon-bar"></span>
    </button>
  
    <a class="navbar-brand" href="../index.html">Center for Future Media, UESTC</a>
  </div>
  <div class="collapse navbar-collapse" id="navbar-collapse-1">
    <ul class="nav navbar-nav navbar-right">
    <li><a href="../index.html">Home</a></li>
    <li><a href="index.html">Research</a></li>
    <li><a href="../team/index.html">Member</a></li>
    <li><a href="../publications/index.html">Publications</a></li>
    <li><a href="../seminar/index.html">Seminar</a></li>
    </ul>
  </div>
  </div>
</div>
</div>

<div class="container-fluid">
  <div class="row">
    <div id="textid" class="col-sm-12">
      <center><h1>Research</h1></center>

<h3 id="work">Part of our achievement</h3>

  <p><b> 1. Visual Question Answering </b></p>

<p>Visual Question Answering is that given an image or a video and a related question, the proposed algorithm can answer the question correctly based on the visual information. Most existing methods are mainly based on recurrent neural networks (RNNs) with attention. But they are time-consuming and having difficulties in modeling long range dependencies due to the sequential nature of RNNs. </p>
<p><center><img src="vqa.jpg" alt="" style="width:600px; border: 10px" /></center></p>
<p>To tackle this issue, we propose a new architecture, Positional Self-Attention with Co-Attention (PSAC), which does not require RNNs for video question answering. The proposed Positional Self-Attention Block can calculate the response at each position by attending to all positions within the same sequence and then add representations of absolute positions. Therefore, PSAC can exploit the global dependencies of question and temporal information in the video and make the process of question and video encoding executed in parallel.</p>
This <a href="http://staff.ustc.edu.cn/~hexn/papers/aaai19-VideoQA.pdf"> paper</a> is accepted as an oral paper by AAAI-2019.

<p><b> 2. Face Aging </b></p>
<p>Face aging and rejuvenation aims to predict the
face of a person at different ages. While tremendous progresses
have been made in this topic, there are two central problems
remaining largely unsolved:<li>the majority of prior works
require sequential training data, which is very rare in real
scenarios;</li> <li> how to simultaneously render aging face and
preserve personality.</li></p>
<p><center><img src="face.png" alt = "" style = "width:500px;  float: left;"/></center></p>
<p>To tackle these issues, we
develop a novel dual conditional GANs (AgeGAN) mechanism,
which enables face aging and rejuvenation to be trained from
multiple sets of unlabeled face images with different ages. In
our architecture, the primal conditional GAN transforms a face
image to other ages based on the age condition, while the
dual conditional GAN learns to invert the task. Hence a loss
function that accounts for the reconstruction error of images can
preserve the personal identity, while the discriminators on the
generated images learn the transition patterns (e.g., the shape and
texture changes between age groups) and guide the generation
of age-specific photo-realistic faces. </p>

<p>We further improve our
networks, termed AgeGAN++, in which we share the weights
between the primal part and the dual part to ensure a more
stable training process. Moreover, in order to get more sensible
results, a representation disentanglement component is integrated
with the latent facial representation, and a novel enhanced
discriminator is applied on the generated images of AgeGAN++.
Experimental results on two public datasets demonstrate the
appealing performance of the proposed methods by comparing
with the state-of-the-art methods. </p>


<p><b> 3. Image retrival </b></p>
Our research interests are in image retrieval, hashing and vector quantization. 
<p><center><img src="https://i.loli.net/2019/09/22/jST1hmMRCquo9Vs.png" alt="" style="width: 600px;  border: 10px" /></center></p>
<p>The figure shows our Deep Recurrent Quantization (DRQ) model which is trained once and can generate sequential binary codes. It is the first to combine recurrent network and quantization, which significantly reduces the codebook size. The code length can be easily controlled by adjusting the number of recurrent iterations. Experimental results on the benchark datasets show that our model achieves comparable or even better performance compared with the state-of-the-arts for image retrieval. But it requires much less number of parameters and training times. This work is accepted as a conference paper in IJCAI-19. <a href="https://www.ijcai.org/proceedings/2019/128">[Paper link]</a>. <a href="https://github.com/cfm-uestc/DRQ">[Source code]</a>.</p> 
Other works:
<li>Deep Progressive Quantization (accepted in IJCAI-19): <a href="https://www.ijcai.org/proceedings/2019/102">[Paper link]</a>. <a href="https://github.com/cfm-uestc/DPQ">[Source code]</a>.</li>






<h3 id="work">Exploring</h3>
    <p><b> 1. Video object segmentation</b></p>

    <p>
      Video Object Segmentation is a task that separating a foreground object from a video sequence. We focus on semi-supervised VOS in which the ground truth segmentation masks of one or multiple objects are given for the first frame in a video. VOS is a fundamental task
in computer vision, with important applications including video editing, robotics, and self-driving cars. 
    </p>
            <p><center><img src="segmentation.jpg" alt="" style="width:600px; border: 10px" /></center></p>
    <p><b> 2. Visual-and-language Navigation </b></p>
    <p>    VLN requires an embodied agent to follow natural language instructions to navigate from a starting pose to a goal location in the Matterport3D Simulator(a new large-scale visual RL simulation environment).</p><br>
    <table border="0" align="center" cellpadding="0" cellspacing="0">
      <tr>
        <td valign="top">
        <img src="VLN.jpg" alt="" style="width: 300px;  border: 10px" /></td>
        <td valign="top">
        <img src="VLN2.jpg" alt="" style="width: 250px;  border: 10px" /></td>
        <td valign="top">
        <img src="VLN3.jpg" alt="" style="width: 300px;  border: 10px" /></td>
      </tr>
    </table>
    <p><b> 3. Adversarial Attack </b></p>
    <p><img src="FGSM.jpg" alt="" style="width: 450px; float: left; border: 10px" /></p>
    <p>Recent studies show that deep neural network are vulnerable to adversarial attacks in the form of subtle perturbations to inputs that lead a model to predict incorrect outputs. In the picture left, we can't see any difference between two images, but DNN really fail. For our group, It's really intersting to understand why it will happen. <br><i>Maybe you still feel it is a little boring, don't care it, let's see an interesting 
      <a href = "https://www.youtube.com/watch?v=WXnQjbZ1e7Y&feature=youtu.be">video</a>. </i>This video is from paper "On Physical Adversarial Patches for Object Detection(arXiv 2019)".<br>
      There are also many other intersting application, explore it and make fun!
</p>
  </div>

</div>
</div>

<div id="footer" class="panel">
  <div class="panel-footer">
   <div class="container-fluid">
     <div class="row">
      <center>
        <div class="col-sm-12">
         Contact: Room A305, innovation center, University of Electronic Science and Technology of China (<a href="https://www.amap.com/search?query=%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E6%B8%85%E6%B0%B4%E6%B2%B3%E6%A0%A1%E5%8C%BA%E5%88%9B%E6%96%B0%E4%B8%AD%E5%BF%83&city=510100&geoobj=103.851502%7C30.542145%7C104.389832%7C30.782536&zoom=12">Maps</a>) <br />
                   If there are any bug, please contact <a href="mailto:qilong.zhangdl@gmail.com">qilong.zhangdl@gmail.com</a>. Thank you!
          (2019-9-25) <br />
        </center>
      </div>
    </div>
  </div>
</div>
</div>



<script src="../js/jquery.min.js"></script>
<script src="../js/bootstrap.min.js"></script>


</body>

</html>
